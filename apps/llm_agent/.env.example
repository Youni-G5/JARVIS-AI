# LLM Configuration
LLM_MODEL_PATH=/path/to/llama-model.gguf
MAX_TOKENS=2048
TEMPERATURE=0.7

# Services hosts
MEMORY_HOST=localhost:8003
ACTION_EXEC_HOST=localhost:8001
NOTIFY_HOST=localhost:8004
